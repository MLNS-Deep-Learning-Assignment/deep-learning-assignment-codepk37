{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset 2775\n",
      "torch.Size([16, 1, 4, 10])\n",
      "tensor([[[0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]]])\n",
      "tensor(25)\n",
      "5857.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Custom Dataset Class\n",
    "class MNISTDigitsDataset(Dataset):\n",
    "    def __init__(self, root_dirs, transform=None):\n",
    "        self.image_paths = []\n",
    "        for root_dir in root_dirs:\n",
    "            for file in os.listdir(root_dir):\n",
    "                if file.endswith('.png'):\n",
    "                    self.image_paths.append(os.path.join(root_dir, file))\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "\n",
    "        # Load the image\n",
    "        image_name = os.path.basename(image_path)\n",
    "        # Extract label from the filename (e.g., '0428.png' -> [0, 4, 2, 8])\n",
    "        label = [int(digit) for digit in image_name.split('.')[0]]\n",
    "\n",
    "        label_num = torch.sum(torch.tensor(label)).item()  # Sum the elements and convert to a Python scalar\n",
    "\n",
    "\n",
    "        # print(\"label \",label_num, \"sum \",sum(label))\n",
    "        # Convert label to one-hot encoding (4 digits, 10 classes per digit)\n",
    "        one_hot_label = torch.zeros(40, dtype=torch.long)  # 10 classes * 4 digits = 40\n",
    "        for i, digit in enumerate(label):\n",
    "            one_hot_label[i * 10 + digit] = 1  # Set the corresponding class to 1\n",
    "\n",
    "\n",
    "        return one_hot_label.view(-1,4,10) , label_num ,image_name\n",
    "\n",
    "\n",
    "# Create Dataset and DataLoader\n",
    "#image_dir = r\"./exterim/images\"  # Update with your path\n",
    "root_dirs = [\n",
    "    r\"./exterim/images\",  # Update with your paths\n",
    "    r\"./exterim/images2\"  # Add additional directories here\n",
    "]\n",
    "\n",
    "dataset = MNISTDigitsDataset(root_dirs=root_dirs)\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "print(\"length of dataset\",len(dataset))\n",
    "train_size = int(0.9 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "\n",
    "\n",
    "# DataLoader for batching\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# DataLoader for training and test sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Example usage\n",
    "for one_hot_label, label_num,label in train_loader:\n",
    "    print(one_hot_label.shape)  # Should print torch.Size([32, 1, 40, 168])\n",
    "    # print(label_num.shape)  # Should print torch.Size([32, 40]) for one-hot encoded labels\n",
    "\n",
    "    print(one_hot_label[0])\n",
    "    print(label_num[0])\n",
    "    print(label[0])\n",
    "\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MNISTSumModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTSumModel, self).__init__()\n",
    "        \n",
    "        # MLP layers (flatten the 1x4x10 output)\n",
    "        self.fc1 = nn.Linear(40, 64)  # 40 input features (4 digits * 10 classes)\n",
    "        self.fc22 = nn.Linear(64, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)  # Output a single scalar (the sum of digits)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply softmax to each 10-length vector (per digit)\n",
    "        x = x.float()\n",
    "        x = F.softmax(x, dim=-1)\n",
    "        \n",
    "        # Flatten the input (4 digits * 10 classes)\n",
    "        x = x.view(-1, 40)  # Shape becomes (batch_size, 40)\n",
    "\n",
    "        # MLP layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc22(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)  # Single scalar output\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Loss: 104.8147\n",
      "Epoch [2/25], Loss: 26.4548\n",
      "Epoch [3/25], Loss: 16.7540\n",
      "Epoch [4/25], Loss: 2.5075\n",
      "Epoch [5/25], Loss: 0.0616\n",
      "Epoch [6/25], Loss: 0.0073\n",
      "Epoch [7/25], Loss: 0.0036\n",
      "Epoch [8/25], Loss: 0.0025\n",
      "Epoch [9/25], Loss: 0.0018\n",
      "Epoch [10/25], Loss: 0.0014\n",
      "Epoch [11/25], Loss: 0.0011\n",
      "Epoch [12/25], Loss: 0.0009\n",
      "Epoch [13/25], Loss: 0.0007\n",
      "Epoch [14/25], Loss: 0.0006\n",
      "Epoch [15/25], Loss: 0.0005\n",
      "Epoch [16/25], Loss: 0.0004\n",
      "Epoch [17/25], Loss: 0.0003\n",
      "Epoch [18/25], Loss: 0.0003\n",
      "Epoch [19/25], Loss: 0.0003\n",
      "Epoch [20/25], Loss: 0.0002\n",
      "Epoch [21/25], Loss: 0.0002\n",
      "Epoch [22/25], Loss: 0.0002\n",
      "Epoch [23/25], Loss: 0.0002\n",
      "Epoch [24/25], Loss: 0.0001\n",
      "Epoch [25/25], Loss: 0.0001\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Instantiate the model\n",
    "model = MNISTSumModel()\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()  # Mean Squared Error Loss for regression\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "epochs = 25  # Set number of epochs\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for one_hot_label, label_num, _ in train_loader:\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(one_hot_label)\n",
    "        \n",
    "        # Compute loss (compare output to label_num)\n",
    "        loss = criterion(output.squeeze(), label_num.float())  # Squeeze to remove extra dimensions\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'checkpoints/decoder.pth') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0002\n",
      "Actual vs Predicted:\n",
      "Actual: 20, Predicted: 20.0027\n",
      "Actual: 23, Predicted: 23.0012\n",
      "Actual: 7, Predicted: 7.0282\n",
      "Actual: 19, Predicted: 19.0077\n",
      "Actual: 19, Predicted: 19.0017\n",
      "Actual: 27, Predicted: 27.0027\n",
      "Actual: 24, Predicted: 24.0052\n",
      "Actual: 5, Predicted: 5.0744\n",
      "Actual: 13, Predicted: 13.0038\n",
      "Actual: 14, Predicted: 14.0032\n",
      "Actual: 29, Predicted: 29.0070\n",
      "Actual: 21, Predicted: 21.0086\n",
      "Actual: 16, Predicted: 16.0037\n",
      "Actual: 18, Predicted: 18.0062\n",
      "Actual: 13, Predicted: 13.0070\n",
      "Actual: 16, Predicted: 16.0095\n",
      "Actual: 21, Predicted: 20.9999\n",
      "Actual: 9, Predicted: 9.0041\n",
      "Actual: 17, Predicted: 17.0069\n",
      "Actual: 19, Predicted: 19.0091\n",
      "Actual: 9, Predicted: 9.0028\n",
      "Actual: 14, Predicted: 14.0045\n",
      "Actual: 6, Predicted: 5.9957\n",
      "Actual: 18, Predicted: 18.0033\n",
      "Actual: 18, Predicted: 18.0053\n",
      "Actual: 17, Predicted: 17.0017\n",
      "Actual: 24, Predicted: 24.0103\n",
      "Actual: 11, Predicted: 11.0039\n",
      "Actual: 9, Predicted: 9.0067\n",
      "Actual: 15, Predicted: 15.0054\n",
      "Actual: 20, Predicted: 20.0105\n",
      "Actual: 17, Predicted: 17.0038\n",
      "Actual: 19, Predicted: 19.0004\n",
      "Actual: 12, Predicted: 12.0053\n",
      "Actual: 20, Predicted: 20.0016\n",
      "Actual: 25, Predicted: 25.0098\n",
      "Actual: 21, Predicted: 21.0061\n",
      "Actual: 19, Predicted: 19.0007\n",
      "Actual: 21, Predicted: 21.0105\n",
      "Actual: 21, Predicted: 21.0027\n",
      "Actual: 16, Predicted: 16.0049\n",
      "Actual: 23, Predicted: 23.0078\n",
      "Actual: 20, Predicted: 20.0092\n",
      "Actual: 10, Predicted: 10.0011\n",
      "Actual: 19, Predicted: 19.0049\n",
      "Actual: 13, Predicted: 12.9972\n",
      "Actual: 13, Predicted: 13.0072\n",
      "Actual: 22, Predicted: 22.0094\n",
      "Actual: 10, Predicted: 10.0078\n",
      "Actual: 26, Predicted: 26.0049\n",
      "Actual: 33, Predicted: 33.0056\n",
      "Actual: 14, Predicted: 14.0030\n",
      "Actual: 14, Predicted: 14.0072\n",
      "Actual: 18, Predicted: 18.0013\n",
      "Actual: 10, Predicted: 10.0042\n",
      "Actual: 14, Predicted: 14.0007\n",
      "Actual: 14, Predicted: 14.0037\n",
      "Actual: 17, Predicted: 17.0008\n",
      "Actual: 16, Predicted: 16.0131\n",
      "Actual: 23, Predicted: 23.0050\n",
      "Actual: 28, Predicted: 28.0087\n",
      "Actual: 29, Predicted: 29.0064\n",
      "Actual: 14, Predicted: 14.0076\n",
      "Actual: 11, Predicted: 11.0067\n",
      "Actual: 21, Predicted: 21.0032\n",
      "Actual: 18, Predicted: 18.0017\n",
      "Actual: 15, Predicted: 15.0000\n",
      "Actual: 18, Predicted: 18.0000\n",
      "Actual: 15, Predicted: 15.0027\n",
      "Actual: 20, Predicted: 20.0055\n",
      "Actual: 23, Predicted: 23.0056\n",
      "Actual: 30, Predicted: 30.0047\n",
      "Actual: 12, Predicted: 11.9995\n",
      "Actual: 20, Predicted: 20.0019\n",
      "Actual: 13, Predicted: 13.0054\n",
      "Actual: 17, Predicted: 17.0048\n",
      "Actual: 27, Predicted: 27.0024\n",
      "Actual: 17, Predicted: 17.0033\n",
      "Actual: 11, Predicted: 11.0040\n",
      "Actual: 9, Predicted: 9.0078\n",
      "Actual: 29, Predicted: 29.0001\n",
      "Actual: 18, Predicted: 18.0066\n",
      "Actual: 18, Predicted: 18.0017\n",
      "Actual: 15, Predicted: 15.0028\n",
      "Actual: 14, Predicted: 14.0045\n",
      "Actual: 6, Predicted: 5.9752\n",
      "Actual: 16, Predicted: 16.0088\n",
      "Actual: 17, Predicted: 17.0056\n",
      "Actual: 26, Predicted: 26.0015\n",
      "Actual: 18, Predicted: 18.0049\n",
      "Actual: 22, Predicted: 22.0115\n",
      "Actual: 15, Predicted: 14.9998\n",
      "Actual: 14, Predicted: 13.9984\n",
      "Actual: 17, Predicted: 17.0057\n",
      "Actual: 23, Predicted: 22.9992\n",
      "Actual: 9, Predicted: 9.0048\n",
      "Actual: 15, Predicted: 15.0044\n",
      "Actual: 17, Predicted: 17.0070\n",
      "Actual: 30, Predicted: 30.0061\n",
      "Actual: 14, Predicted: 14.0034\n",
      "Actual: 12, Predicted: 12.0023\n",
      "Actual: 16, Predicted: 16.0019\n",
      "Actual: 13, Predicted: 13.0041\n",
      "Actual: 4, Predicted: 3.9944\n",
      "Actual: 14, Predicted: 14.0039\n",
      "Actual: 13, Predicted: 13.0017\n",
      "Actual: 18, Predicted: 18.0050\n",
      "Actual: 27, Predicted: 27.0020\n",
      "Actual: 18, Predicted: 18.0063\n",
      "Actual: 9, Predicted: 9.0071\n",
      "Actual: 28, Predicted: 28.0029\n",
      "Actual: 21, Predicted: 21.0074\n",
      "Actual: 14, Predicted: 14.0000\n",
      "Actual: 14, Predicted: 14.0030\n",
      "Actual: 19, Predicted: 19.0079\n",
      "Actual: 4, Predicted: 4.1542\n",
      "Actual: 14, Predicted: 14.0055\n",
      "Actual: 5, Predicted: 4.9726\n",
      "Actual: 14, Predicted: 14.0065\n",
      "Actual: 15, Predicted: 15.0009\n",
      "Actual: 21, Predicted: 21.0101\n",
      "Actual: 22, Predicted: 22.0110\n",
      "Actual: 24, Predicted: 24.0001\n",
      "Actual: 16, Predicted: 16.0053\n",
      "Actual: 19, Predicted: 19.0011\n",
      "Actual: 22, Predicted: 22.0038\n",
      "Actual: 27, Predicted: 27.0002\n",
      "Actual: 24, Predicted: 24.0013\n",
      "Actual: 23, Predicted: 23.0085\n",
      "Actual: 17, Predicted: 16.9992\n",
      "Actual: 11, Predicted: 11.0021\n",
      "Actual: 26, Predicted: 26.0078\n",
      "Actual: 11, Predicted: 11.0026\n",
      "Actual: 19, Predicted: 19.0078\n",
      "Actual: 11, Predicted: 11.0015\n",
      "Actual: 19, Predicted: 19.0052\n",
      "Actual: 12, Predicted: 11.9998\n",
      "Actual: 22, Predicted: 22.0039\n",
      "Actual: 20, Predicted: 20.0082\n",
      "Actual: 31, Predicted: 31.0016\n",
      "Actual: 16, Predicted: 16.0038\n",
      "Actual: 7, Predicted: 7.0051\n",
      "Actual: 16, Predicted: 16.0008\n",
      "Actual: 2, Predicted: 2.0713\n",
      "Actual: 23, Predicted: 23.0061\n",
      "Actual: 8, Predicted: 8.0104\n",
      "Actual: 18, Predicted: 18.0039\n",
      "Actual: 25, Predicted: 25.0031\n",
      "Actual: 20, Predicted: 20.0012\n",
      "Actual: 9, Predicted: 9.0017\n",
      "Actual: 5, Predicted: 4.9596\n",
      "Actual: 10, Predicted: 10.0044\n",
      "Actual: 8, Predicted: 8.0353\n",
      "Actual: 21, Predicted: 20.9995\n",
      "Actual: 18, Predicted: 18.0124\n",
      "Actual: 25, Predicted: 25.0053\n",
      "Actual: 19, Predicted: 19.0092\n",
      "Actual: 18, Predicted: 18.0020\n",
      "Actual: 6, Predicted: 5.9862\n",
      "Actual: 23, Predicted: 23.0087\n",
      "Actual: 16, Predicted: 16.0063\n",
      "Actual: 12, Predicted: 12.0061\n",
      "Actual: 17, Predicted: 17.0033\n",
      "Actual: 19, Predicted: 19.0002\n",
      "Actual: 12, Predicted: 12.0074\n",
      "Actual: 26, Predicted: 26.0060\n",
      "Actual: 15, Predicted: 15.0077\n",
      "Actual: 26, Predicted: 26.0071\n",
      "Actual: 20, Predicted: 20.0125\n",
      "Actual: 12, Predicted: 12.0001\n",
      "Actual: 20, Predicted: 20.0043\n",
      "Actual: 28, Predicted: 28.0031\n",
      "Actual: 18, Predicted: 18.0043\n",
      "Actual: 18, Predicted: 18.0010\n",
      "Actual: 19, Predicted: 19.0046\n",
      "Actual: 13, Predicted: 13.0009\n",
      "Actual: 13, Predicted: 13.0072\n",
      "Actual: 17, Predicted: 17.0068\n",
      "Actual: 21, Predicted: 21.0036\n",
      "Actual: 13, Predicted: 13.0065\n",
      "Actual: 15, Predicted: 14.9977\n",
      "Actual: 14, Predicted: 14.0048\n",
      "Actual: 29, Predicted: 29.0004\n",
      "Actual: 25, Predicted: 25.0008\n",
      "Actual: 21, Predicted: 21.0058\n",
      "Actual: 15, Predicted: 15.0075\n",
      "Actual: 26, Predicted: 26.0084\n",
      "Actual: 20, Predicted: 20.0014\n",
      "Actual: 22, Predicted: 22.0089\n",
      "Actual: 17, Predicted: 17.0090\n",
      "Actual: 19, Predicted: 19.0013\n",
      "Actual: 14, Predicted: 14.0055\n",
      "Actual: 32, Predicted: 32.0040\n",
      "Actual: 26, Predicted: 26.0036\n",
      "Actual: 26, Predicted: 26.0006\n",
      "Actual: 29, Predicted: 29.0028\n",
      "Actual: 14, Predicted: 14.0081\n",
      "Actual: 23, Predicted: 23.0031\n",
      "Actual: 21, Predicted: 21.0037\n",
      "Actual: 14, Predicted: 14.0059\n",
      "Actual: 21, Predicted: 21.0027\n",
      "Actual: 13, Predicted: 12.9957\n",
      "Actual: 8, Predicted: 8.0065\n",
      "Actual: 23, Predicted: 23.0027\n",
      "Actual: 12, Predicted: 12.0030\n",
      "Actual: 20, Predicted: 20.0038\n",
      "Actual: 3, Predicted: 2.9136\n",
      "Actual: 16, Predicted: 16.0078\n",
      "Actual: 9, Predicted: 9.0009\n",
      "Actual: 16, Predicted: 15.9972\n",
      "Actual: 11, Predicted: 11.0019\n",
      "Actual: 15, Predicted: 15.0051\n",
      "Actual: 14, Predicted: 13.9990\n",
      "Actual: 15, Predicted: 15.0084\n",
      "Actual: 11, Predicted: 11.0007\n",
      "Actual: 17, Predicted: 17.0032\n",
      "Actual: 11, Predicted: 11.0019\n",
      "Actual: 18, Predicted: 17.9984\n",
      "Actual: 17, Predicted: 17.0046\n",
      "Actual: 26, Predicted: 26.0026\n",
      "Actual: 20, Predicted: 20.0024\n",
      "Actual: 17, Predicted: 17.0031\n",
      "Actual: 11, Predicted: 11.0060\n",
      "Actual: 26, Predicted: 26.0038\n",
      "Actual: 21, Predicted: 21.0066\n",
      "Actual: 14, Predicted: 14.0022\n",
      "Actual: 25, Predicted: 25.0015\n",
      "Actual: 12, Predicted: 12.0081\n",
      "Actual: 25, Predicted: 24.9997\n",
      "Actual: 23, Predicted: 23.0059\n",
      "Actual: 21, Predicted: 21.0093\n",
      "Actual: 11, Predicted: 11.0104\n",
      "Actual: 18, Predicted: 18.0035\n",
      "Actual: 9, Predicted: 9.0075\n",
      "Actual: 23, Predicted: 23.0047\n",
      "Actual: 23, Predicted: 23.0005\n",
      "Actual: 13, Predicted: 13.0024\n",
      "Actual: 13, Predicted: 13.0007\n",
      "Actual: 23, Predicted: 23.0049\n",
      "Actual: 17, Predicted: 17.0049\n",
      "Actual: 14, Predicted: 14.0031\n",
      "Actual: 21, Predicted: 21.0032\n",
      "Actual: 26, Predicted: 26.0010\n",
      "Actual: 17, Predicted: 17.0054\n",
      "Actual: 17, Predicted: 17.0006\n",
      "Actual: 27, Predicted: 27.0022\n",
      "Actual: 22, Predicted: 22.0010\n",
      "Actual: 25, Predicted: 25.0066\n",
      "Actual: 20, Predicted: 20.0035\n",
      "Actual: 18, Predicted: 18.0070\n",
      "Actual: 25, Predicted: 25.0079\n",
      "Actual: 10, Predicted: 10.0015\n",
      "Actual: 19, Predicted: 19.0091\n",
      "Actual: 13, Predicted: 13.0088\n",
      "Actual: 12, Predicted: 12.0093\n",
      "Actual: 24, Predicted: 24.0040\n",
      "Actual: 17, Predicted: 17.0069\n",
      "Actual: 17, Predicted: 17.0104\n",
      "Actual: 17, Predicted: 17.0049\n",
      "Actual: 23, Predicted: 23.0070\n",
      "Actual: 27, Predicted: 27.0036\n",
      "Actual: 20, Predicted: 20.0033\n",
      "Actual: 17, Predicted: 17.0042\n",
      "Actual: 10, Predicted: 10.0007\n",
      "Actual: 22, Predicted: 22.0067\n",
      "Actual: 12, Predicted: 12.0068\n",
      "Actual: 16, Predicted: 16.0000\n",
      "Actual: 31, Predicted: 31.0073\n",
      "Actual: 23, Predicted: 23.0020\n",
      "Actual: 10, Predicted: 10.0069\n",
      "Actual: 28, Predicted: 28.0057\n",
      "Actual: 26, Predicted: 26.0026\n",
      "Actual: 12, Predicted: 12.0077\n",
      "Actual: 9, Predicted: 9.0040\n",
      "Actual: 18, Predicted: 18.0008\n",
      "Actual: 8, Predicted: 7.9983\n",
      "Actual: 29, Predicted: 29.0050\n",
      "Actual: 18, Predicted: 18.0032\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set model to evaluation mode\n",
    "test_loss = 0.0\n",
    "predictions = []  # List to store predicted values\n",
    "actuals = []  # List to store actual values\n",
    "\n",
    "with torch.no_grad():\n",
    "    for one_hot_label, label_num, _ in test_loader:\n",
    "        output = model(one_hot_label)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(output.squeeze(), label_num.float())\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        # Append the actual and predicted values\n",
    "        predictions.extend(output.squeeze().cpu().numpy())  # Convert tensor to numpy for easier printing\n",
    "        actuals.extend(label_num.cpu().numpy())  # Convert tensor to numpy for easier printing\n",
    "\n",
    "# Calculate average test loss\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "print(f\"Test Loss: {avg_test_loss:.4f}\")\n",
    "\n",
    "# Print actual vs predicted values\n",
    "print(\"Actual vs Predicted:\")\n",
    "for actual, predicted in zip(actuals, predictions):\n",
    "    print(f\"Actual: {actual}, Predicted: {predicted:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from decoder.pth\n",
      "Predicted: tensor([[20.0027],\n",
      "        [23.0012],\n",
      "        [ 7.0282],\n",
      "        [19.0077],\n",
      "        [19.0017],\n",
      "        [27.0027],\n",
      "        [24.0052],\n",
      "        [ 5.0744],\n",
      "        [13.0038],\n",
      "        [14.0032],\n",
      "        [29.0070],\n",
      "        [21.0086],\n",
      "        [16.0037],\n",
      "        [18.0062],\n",
      "        [13.0070],\n",
      "        [16.0095]]), Actual: tensor([20, 23,  7, 19, 19, 27, 24,  5, 13, 14, 29, 21, 16, 18, 13, 16])\n",
      "Predicted: tensor([[20.9999],\n",
      "        [ 9.0041],\n",
      "        [17.0069],\n",
      "        [19.0091],\n",
      "        [ 9.0028],\n",
      "        [14.0045],\n",
      "        [ 5.9957],\n",
      "        [18.0033],\n",
      "        [18.0053],\n",
      "        [17.0017],\n",
      "        [24.0103],\n",
      "        [11.0039],\n",
      "        [ 9.0067],\n",
      "        [15.0054],\n",
      "        [20.0105],\n",
      "        [17.0038]]), Actual: tensor([21,  9, 17, 19,  9, 14,  6, 18, 18, 17, 24, 11,  9, 15, 20, 17])\n",
      "Predicted: tensor([[19.0004],\n",
      "        [12.0053],\n",
      "        [20.0016],\n",
      "        [25.0098],\n",
      "        [21.0061],\n",
      "        [19.0007],\n",
      "        [21.0105],\n",
      "        [21.0027],\n",
      "        [16.0049],\n",
      "        [23.0078],\n",
      "        [20.0092],\n",
      "        [10.0011],\n",
      "        [19.0049],\n",
      "        [12.9972],\n",
      "        [13.0072],\n",
      "        [22.0094]]), Actual: tensor([19, 12, 20, 25, 21, 19, 21, 21, 16, 23, 20, 10, 19, 13, 13, 22])\n",
      "Predicted: tensor([[10.0078],\n",
      "        [26.0049],\n",
      "        [33.0056],\n",
      "        [14.0030],\n",
      "        [14.0072],\n",
      "        [18.0013],\n",
      "        [10.0042],\n",
      "        [14.0007],\n",
      "        [14.0037],\n",
      "        [17.0008],\n",
      "        [16.0131],\n",
      "        [23.0050],\n",
      "        [28.0087],\n",
      "        [29.0064],\n",
      "        [14.0076],\n",
      "        [11.0067]]), Actual: tensor([10, 26, 33, 14, 14, 18, 10, 14, 14, 17, 16, 23, 28, 29, 14, 11])\n",
      "Predicted: tensor([[21.0032],\n",
      "        [18.0017],\n",
      "        [15.0000],\n",
      "        [18.0000],\n",
      "        [15.0027],\n",
      "        [20.0055],\n",
      "        [23.0056],\n",
      "        [30.0047],\n",
      "        [11.9995],\n",
      "        [20.0019],\n",
      "        [13.0054],\n",
      "        [17.0048],\n",
      "        [27.0024],\n",
      "        [17.0033],\n",
      "        [11.0040],\n",
      "        [ 9.0078]]), Actual: tensor([21, 18, 15, 18, 15, 20, 23, 30, 12, 20, 13, 17, 27, 17, 11,  9])\n",
      "Predicted: tensor([[29.0001],\n",
      "        [18.0066],\n",
      "        [18.0017],\n",
      "        [15.0028],\n",
      "        [14.0045],\n",
      "        [ 5.9752],\n",
      "        [16.0088],\n",
      "        [17.0056],\n",
      "        [26.0015],\n",
      "        [18.0049],\n",
      "        [22.0115],\n",
      "        [14.9998],\n",
      "        [13.9984],\n",
      "        [17.0057],\n",
      "        [22.9992],\n",
      "        [ 9.0048]]), Actual: tensor([29, 18, 18, 15, 14,  6, 16, 17, 26, 18, 22, 15, 14, 17, 23,  9])\n",
      "Predicted: tensor([[15.0044],\n",
      "        [17.0070],\n",
      "        [30.0061],\n",
      "        [14.0034],\n",
      "        [12.0023],\n",
      "        [16.0019],\n",
      "        [13.0041],\n",
      "        [ 3.9944],\n",
      "        [14.0039],\n",
      "        [13.0017],\n",
      "        [18.0050],\n",
      "        [27.0020],\n",
      "        [18.0063],\n",
      "        [ 9.0071],\n",
      "        [28.0029],\n",
      "        [21.0074]]), Actual: tensor([15, 17, 30, 14, 12, 16, 13,  4, 14, 13, 18, 27, 18,  9, 28, 21])\n",
      "Predicted: tensor([[14.0000],\n",
      "        [14.0030],\n",
      "        [19.0079],\n",
      "        [ 4.1542],\n",
      "        [14.0055],\n",
      "        [ 4.9726],\n",
      "        [14.0065],\n",
      "        [15.0009],\n",
      "        [21.0101],\n",
      "        [22.0110],\n",
      "        [24.0001],\n",
      "        [16.0053],\n",
      "        [19.0011],\n",
      "        [22.0038],\n",
      "        [27.0002],\n",
      "        [24.0013]]), Actual: tensor([14, 14, 19,  4, 14,  5, 14, 15, 21, 22, 24, 16, 19, 22, 27, 24])\n",
      "Predicted: tensor([[23.0085],\n",
      "        [16.9992],\n",
      "        [11.0021],\n",
      "        [26.0078],\n",
      "        [11.0026],\n",
      "        [19.0078],\n",
      "        [11.0015],\n",
      "        [19.0052],\n",
      "        [11.9998],\n",
      "        [22.0039],\n",
      "        [20.0082],\n",
      "        [31.0016],\n",
      "        [16.0038],\n",
      "        [ 7.0051],\n",
      "        [16.0008],\n",
      "        [ 2.0713]]), Actual: tensor([23, 17, 11, 26, 11, 19, 11, 19, 12, 22, 20, 31, 16,  7, 16,  2])\n",
      "Predicted: tensor([[23.0061],\n",
      "        [ 8.0104],\n",
      "        [18.0039],\n",
      "        [25.0031],\n",
      "        [20.0012],\n",
      "        [ 9.0017],\n",
      "        [ 4.9596],\n",
      "        [10.0044],\n",
      "        [ 8.0353],\n",
      "        [20.9995],\n",
      "        [18.0124],\n",
      "        [25.0053],\n",
      "        [19.0092],\n",
      "        [18.0020],\n",
      "        [ 5.9862],\n",
      "        [23.0087]]), Actual: tensor([23,  8, 18, 25, 20,  9,  5, 10,  8, 21, 18, 25, 19, 18,  6, 23])\n",
      "Predicted: tensor([[16.0063],\n",
      "        [12.0061],\n",
      "        [17.0033],\n",
      "        [19.0002],\n",
      "        [12.0074],\n",
      "        [26.0060],\n",
      "        [15.0077],\n",
      "        [26.0071],\n",
      "        [20.0125],\n",
      "        [12.0001],\n",
      "        [20.0043],\n",
      "        [28.0031],\n",
      "        [18.0043],\n",
      "        [18.0010],\n",
      "        [19.0046],\n",
      "        [13.0009]]), Actual: tensor([16, 12, 17, 19, 12, 26, 15, 26, 20, 12, 20, 28, 18, 18, 19, 13])\n",
      "Predicted: tensor([[13.0072],\n",
      "        [17.0068],\n",
      "        [21.0036],\n",
      "        [13.0065],\n",
      "        [14.9977],\n",
      "        [14.0048],\n",
      "        [29.0004],\n",
      "        [25.0008],\n",
      "        [21.0058],\n",
      "        [15.0075],\n",
      "        [26.0084],\n",
      "        [20.0014],\n",
      "        [22.0089],\n",
      "        [17.0090],\n",
      "        [19.0013],\n",
      "        [14.0055]]), Actual: tensor([13, 17, 21, 13, 15, 14, 29, 25, 21, 15, 26, 20, 22, 17, 19, 14])\n",
      "Predicted: tensor([[32.0040],\n",
      "        [26.0036],\n",
      "        [26.0006],\n",
      "        [29.0028],\n",
      "        [14.0081],\n",
      "        [23.0031],\n",
      "        [21.0037],\n",
      "        [14.0059],\n",
      "        [21.0027],\n",
      "        [12.9957],\n",
      "        [ 8.0065],\n",
      "        [23.0027],\n",
      "        [12.0030],\n",
      "        [20.0038],\n",
      "        [ 2.9136],\n",
      "        [16.0078]]), Actual: tensor([32, 26, 26, 29, 14, 23, 21, 14, 21, 13,  8, 23, 12, 20,  3, 16])\n",
      "Predicted: tensor([[ 9.0009],\n",
      "        [15.9972],\n",
      "        [11.0019],\n",
      "        [15.0051],\n",
      "        [13.9990],\n",
      "        [15.0084],\n",
      "        [11.0007],\n",
      "        [17.0032],\n",
      "        [11.0019],\n",
      "        [17.9984],\n",
      "        [17.0046],\n",
      "        [26.0026],\n",
      "        [20.0024],\n",
      "        [17.0031],\n",
      "        [11.0060],\n",
      "        [26.0038]]), Actual: tensor([ 9, 16, 11, 15, 14, 15, 11, 17, 11, 18, 17, 26, 20, 17, 11, 26])\n",
      "Predicted: tensor([[21.0066],\n",
      "        [14.0022],\n",
      "        [25.0015],\n",
      "        [12.0081],\n",
      "        [24.9997],\n",
      "        [23.0059],\n",
      "        [21.0093],\n",
      "        [11.0104],\n",
      "        [18.0035],\n",
      "        [ 9.0075],\n",
      "        [23.0047],\n",
      "        [23.0005],\n",
      "        [13.0024],\n",
      "        [13.0007],\n",
      "        [23.0049],\n",
      "        [17.0049]]), Actual: tensor([21, 14, 25, 12, 25, 23, 21, 11, 18,  9, 23, 23, 13, 13, 23, 17])\n",
      "Predicted: tensor([[14.0031],\n",
      "        [21.0032],\n",
      "        [26.0010],\n",
      "        [17.0054],\n",
      "        [17.0006],\n",
      "        [27.0022],\n",
      "        [22.0010],\n",
      "        [25.0066],\n",
      "        [20.0035],\n",
      "        [18.0070],\n",
      "        [25.0079],\n",
      "        [10.0015],\n",
      "        [19.0091],\n",
      "        [13.0088],\n",
      "        [12.0093],\n",
      "        [24.0040]]), Actual: tensor([14, 21, 26, 17, 17, 27, 22, 25, 20, 18, 25, 10, 19, 13, 12, 24])\n",
      "Predicted: tensor([[17.0069],\n",
      "        [17.0104],\n",
      "        [17.0049],\n",
      "        [23.0070],\n",
      "        [27.0036],\n",
      "        [20.0033],\n",
      "        [17.0042],\n",
      "        [10.0007],\n",
      "        [22.0067],\n",
      "        [12.0068],\n",
      "        [16.0000],\n",
      "        [31.0073],\n",
      "        [23.0020],\n",
      "        [10.0069],\n",
      "        [28.0057],\n",
      "        [26.0026]]), Actual: tensor([17, 17, 17, 23, 27, 20, 17, 10, 22, 12, 16, 31, 23, 10, 28, 26])\n",
      "Predicted: tensor([[12.0077],\n",
      "        [ 9.0040],\n",
      "        [18.0008],\n",
      "        [ 7.9983],\n",
      "        [29.0050],\n",
      "        [18.0032]]), Actual: tensor([12,  9, 18,  8, 29, 18])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pavan\\AppData\\Local\\Temp\\ipykernel_25108\\1446072894.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('checkpoints/decoder.pth'))\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model again\n",
    "model = MNISTSumModel()\n",
    "\n",
    "# Load the saved model weights\n",
    "model.load_state_dict(torch.load('checkpoints/decoder.pth'))\n",
    "model.eval()  # Set the model to evaluation mode for inference\n",
    "print(\"Model loaded from decoder.pth\")\n",
    "\n",
    "# Example inference loop\n",
    "with torch.no_grad():\n",
    "    for one_hot_label, label_num, image_name in test_loader:\n",
    "        output = model(one_hot_label)\n",
    "        print(f\"Predicted: {output}, Actual: {label_num}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
